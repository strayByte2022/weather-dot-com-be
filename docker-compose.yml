services:
  broker-1:
    image: apache/kafka:4.0.0
    container_name: broker-1
    ports:
      - "29092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_CLUSTER_ID: "1qWuvkKzQd6kRvirOjNEMQ"
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: "PLAINTEXT://broker-1:19092,PLAINTEXT_HOST://broker-1:9092, CONTROLLER://broker-1:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://broker-1:19092,PLAINTEXT_HOST://localhost:29092"
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker-1:9093,2@broker-2:9093,3@broker-3:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG_RETENTION_HOURS: 336

  broker-2:
    image: apache/kafka:4.0.0
    container_name: broker-2
    ports:
      - "39092:9092"
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_CLUSTER_ID: "1qWuvkKzQd6kRvirOjNEMQ"
      KAFKA_PROCESS_ROLES: broker, controller
      KAFKA_LISTENERS: "PLAINTEXT://broker-2:19092,PLAINTEXT_HOST://broker-2:9092, CONTROLLER://broker-2:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://broker-2:19092,PLAINTEXT_HOST://localhost:39092"
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker-1:9093,2@broker-2:9093,3@broker-3:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG_RETENTION_HOURS: 336

  broker-3:
    image: apache/kafka:4.0.0
    container_name: broker-3
    ports:
      - "49092:9092"
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_CLUSTER_ID: "1qWuvkKzQd6kRvirOjNEMQ"
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: "PLAINTEXT://broker-3:19092,PLAINTEXT_HOST://broker-3:9092,CONTROLLER://broker-3:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://broker-3:19092,PLAINTEXT_HOST://localhost:49092"
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker-1:9093,2@broker-2:9093,3@broker-3:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG_RETENTION_HOURS: 336
  
  ksqldb:
    image: confluentinc/ksqldb-server:0.29.0
    container_name: ksqldb-server
    depends_on:
      - broker-1
      - broker-2
      - broker-3
    ports:
      - "8088:8088"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksqldb"
      KSQL_BOOTSTRAP_SERVERS: "broker-1:19092, broker-2:19092, broker-3:19092"
      KSQL_LISTENERS: "http://0.0.0.0:8088"
      KSQL_KSQL_SERVICE_ID: "ksql_service_"
      KSQL_KSQL_STREAMS_AUTO_OFFSET_RESET: "earliest"
      KSQL_KSQL_STREAMS_NUM_STREAM_THREADS: 4
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_LOG4J_OPTS: "-Dlog4j.configuration=file:/etc/ksqldb/log4j.properties"
      KSQL_OPTS: "-Dconfluent.support.metrics.enable=false"

  ksql-init:
    image: curlimages/curl:latest
    container_name: ksql-init
    depends_on:
      - ksqldb
      - topic-creator
    volumes:
      - ./streaming/submit-ksql.sh:/submit-ksql.sh
      - ./streaming/init.sql:/home/curl_user/init.sql
    entrypoint: ["sh", "/submit-ksql.sh"]

  topic-creator:
    image: apache/kafka:4.0.0
    container_name: topic-creator
    depends_on:
      - broker-1
      - broker-2
      - broker-3
    volumes:
      - ./entrypoint.sh:/entrypoint.sh
    entrypoint: ["/bin/bash", "/entrypoint.sh"]

  namenode:
    image: apache/hadoop:3.4.1
    container_name: namenode
    hostname: namenode
    user: root
    environment:
      - HADOOP_HOME=/opt/hadoop
    volumes:
      - ./hadoop/hadoop_namenode:/opt/hadoop/data/nameNode
      - ./hadoop/hadoop_config:/opt/hadoop/etc/hadoop
      - ./hadoop/start-hdfs.sh:/start-hdfs.sh
    ports:
      - "9870:9870"
    command: [ "/bin/bash", "/start-hdfs.sh" ]
    networks:
      hdfs_network:
        ipv4_address: 172.20.0.2

  datanode1:
    image: apache/hadoop:3.4.1
    container_name: datanode1
    hostname: datanode1
    user: root
    ports:
    - "9864:9864"
    environment:
      - HADOOP_HOME=/opt/hadoop
    volumes:
      - ./hadoop/hadoop_datanode1:/opt/hadoop/data/dataNode
      - ./hadoop/hadoop_config:/opt/hadoop/etc/hadoop
      - ./hadoop/init-datanode.sh:/init-datanode.sh
    depends_on:
      - namenode
    command: [ "/bin/bash", "/init-datanode.sh" ]
    networks:
      hdfs_network:
        ipv4_address: 172.20.0.3

  datanode2:
    image: apache/hadoop:3.4.1
    container_name: datanode2
    hostname: datanode2
    user: root
    ports:
    - "9865:9864"
    environment:
      - HADOOP_HOME=/opt/hadoop
    volumes:
      - ./hadoop/hadoop_datanode2:/opt/hadoop/data/dataNode
      - ./hadoop/hadoop_config:/opt/hadoop/etc/hadoop
      - ./hadoop/init-datanode.sh:/init-datanode.sh
    depends_on:
      - namenode
    command: [ "/bin/bash", "/init-datanode.sh" ]
    networks:
      hdfs_network:
        ipv4_address: 172.20.0.4

  postgresql:
    image: postgres:11
    container_name: postgresql
    env_file: "./pipeline/postgres/.env"
    networks:
      hdfs_network:
        ipv4_address: 172.20.0.5
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U postgres_user -d postgres_db']
      interval: 10s
      timeout: 8s
      retries: 5
  
  user_code:
    build:
      context: .
      dockerfile: ./docker/user/Dockerfile
    container_name: user_code
    image: user_code_image
    restart: always
    env_file: "./pipeline/.env"
    environment:
      DAGSTER_CURRENT_IMAGE: 'user_code_image'
    networks:
      default: {}
      hdfs_network:
        ipv4_address: 172.20.0.6

  webserver:
    build:
      context: .
      dockerfile: ./docker/dagster/Dockerfile
    entrypoint:
      - dagster-webserver
      - -h
      - '0.0.0.0'
      - -p
      - '3000'
      - -w
      - workspace.yaml
    container_name: webserver
    expose:
      - '3000'
    ports:
      - '3000:3000'
    env_file: "./pipeline/.env"
    volumes: # Make docker client accessible so we can terminate containers from the webserver
      - /var/run/docker.sock:/var/run/docker.sock
      - /tmp/io_manager_storage:/tmp/io_manager_storage
    networks:
      hdfs_network:
        ipv4_address: 172.20.0.7
    depends_on:
      postgresql:
        condition: service_healthy
      user_code:
        condition: service_started

  daemon:
    build:
      context: .
      dockerfile: ./docker/dagster/Dockerfile
    entrypoint:
      - dagster-daemon
      - run
    container_name: daemon
    restart: on-failure
    env_file: "./pipeline/.env"
    volumes: # Make docker client accessible so we can launch containers using host docker
      - /var/run/docker.sock:/var/run/docker.sock
      - /tmp/io_manager_storage:/tmp/io_manager_storage
    networks:
      hdfs_network:
        ipv4_address: 172.20.0.8
    depends_on:
      postgresql:
        condition: service_healthy
      user_code:
        condition: service_started

networks:
  hdfs_network:
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16